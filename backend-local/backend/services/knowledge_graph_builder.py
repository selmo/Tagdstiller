"""
Knowledge Graph Builder Service

ë¬¸ì„œ ì „ì²´ë¥¼ Knowledge Graphë¡œ ë³€í™˜í•˜ëŠ” ì „ìš© ì„œë¹„ìŠ¤
LLMì„ ì‚¬ìš©í•˜ì—¬ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•˜ê³  ê·¸ë˜í”„ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from sqlalchemy.orm import Session

from prompts.templates import KnowledgeGraphPrompts, PromptTemplate
from services.local_file_analyzer import LocalFileAnalyzer

logger = logging.getLogger(__name__)


class KnowledgeGraphBuilder:
    """ë¬¸ì„œë¥¼ Knowledge Graphë¡œ ë³€í™˜í•˜ëŠ” ë¹Œë” í´ë˜ìŠ¤"""

    def __init__(self, db: Session):
        self.db = db
        self.analyzer = LocalFileAnalyzer(db)
        self.logger = logging.getLogger(__name__)

    def build_knowledge_graph(
        self,
        text: str,
        file_path: str,
        domain: str = "general",
        structure_info: Optional[Dict[str, Any]] = None,
        llm_config: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        ë¬¸ì„œ í…ìŠ¤íŠ¸ì—ì„œ Knowledge Graph ìƒì„±

        Args:
            text: ë¬¸ì„œ í…ìŠ¤íŠ¸
            file_path: íŒŒì¼ ê²½ë¡œ
            domain: ë¬¸ì„œ ë„ë©”ì¸ (general, technical, academic, business, legal)
            structure_info: ë¬¸ì„œ êµ¬ì¡° ì •ë³´ (ì„ íƒ)
            llm_config: LLM ì„¤ì • (ì„ íƒ)

        Returns:
            Knowledge Graph JSON êµ¬ì¡°
        """
        try:
            self.logger.info(f"ğŸ” Knowledge Graph ìƒì„± ì‹œì‘: {Path(file_path).name} (ë„ë©”ì¸: {domain})")

            # 1. ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            prompt_template = self._get_kg_prompt_template(domain)

            # 2. êµ¬ì¡° ì •ë³´ ê°„ëµí™”
            structure_summary = self._summarize_structure(structure_info) if structure_info else "êµ¬ì¡° ì •ë³´ ì—†ìŒ"

            # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = prompt_template.format(
                text=text[:100000],  # ìµœëŒ€ 100K ë¬¸ì (ì•½ 50K í† í°)
                domain=domain,
                structure_info=structure_summary
            )

            # 4. LLM í˜¸ì¶œ (LocalFileAnalyzerì˜ LLM ê¸°ëŠ¥ í™œìš©)
            llm_response = self._call_llm_for_kg(prompt, llm_config or {})

            if not llm_response.get("success"):
                return self._create_error_result(llm_response.get("error", "LLM í˜¸ì¶œ ì‹¤íŒ¨"))

            # 5. LLM ì‘ë‹µ íŒŒì‹±
            kg_data = self._parse_kg_response(llm_response.get("response", ""))

            # 6. ë©”íƒ€ë°ì´í„° ì¶”ê°€
            kg_result = self._enrich_kg_with_metadata(
                kg_data,
                file_path,
                domain,
                structure_info
            )

            self.logger.info(
                f"âœ… Knowledge Graph ìƒì„± ì™„ë£Œ: "
                f"{kg_result['stats']['entity_count']}ê°œ ì—”í‹°í‹°, "
                f"{kg_result['stats']['relationship_count']}ê°œ ê´€ê³„"
            )

            return kg_result

        except Exception as e:
            self.logger.error(f"âŒ Knowledge Graph ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return self._create_error_result(str(e))

    def _get_kg_prompt_template(self, domain: str) -> PromptTemplate:
        """ë„ë©”ì¸ë³„ KG ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ì„ íƒ"""
        domain_prompts = {
            "general": KnowledgeGraphPrompts.GENERAL_KG_EXTRAION,
            "technical": KnowledgeGraphPrompts.TECHNICAL_KG_EXTRACTION,
            "academic": KnowledgeGraphPrompts.ACADEMIC_KG_EXTRACTION,
            "business": KnowledgeGraphPrompts.BUSINESS_KG_EXTRACTION,
            "legal": KnowledgeGraphPrompts.LEGAL_KG_EXTRACTION,
        }
        return domain_prompts.get(domain, KnowledgeGraphPrompts.GENERAL_KG_EXTRAION)

    def _summarize_structure(self, structure_info: Dict[str, Any]) -> str:
        """ë¬¸ì„œ êµ¬ì¡° ì •ë³´ë¥¼ ê°„ëµí•œ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½"""
        if not structure_info:
            return "êµ¬ì¡° ì •ë³´ ì—†ìŒ"

        try:
            summary_parts = []

            # ë¬¸ì„œ ê¸°ë³¸ ì •ë³´
            doc_info = structure_info.get("documentInfo", {})
            if doc_info:
                title = doc_info.get("title", "ì œëª© ì—†ìŒ")
                doc_type = doc_info.get("documentType", "ë¯¸ë¶„ë¥˜")
                summary_parts.append(f"ë¬¸ì„œ: {title} ({doc_type})")

            # êµ¬ì¡° ë¶„ì„ ìš”ì•½
            structure_analysis = structure_info.get("structureAnalysis", [])
            if structure_analysis:
                section_count = len(structure_analysis)
                summary_parts.append(f"{section_count}ê°œ ì£¼ìš” ì„¹ì…˜")

            # í•µì‹¬ ë‚´ìš© ìš”ì•½
            core_content = structure_info.get("coreContent", {})
            if core_content:
                main_topic = core_content.get("mainTopic", "")
                if main_topic:
                    summary_parts.append(f"ì£¼ì œ: {main_topic}")

            return " | ".join(summary_parts) if summary_parts else "êµ¬ì¡° ì •ë³´ ì—†ìŒ"

        except Exception as e:
            self.logger.warning(f"êµ¬ì¡° ì •ë³´ ìš”ì•½ ì‹¤íŒ¨: {e}")
            return "êµ¬ì¡° ì •ë³´ ì²˜ë¦¬ ì˜¤ë¥˜"

    def _call_llm_for_kg(self, prompt: str, llm_config: Dict[str, Any]) -> Dict[str, Any]:
        """LLM í˜¸ì¶œí•˜ì—¬ Knowledge Graph ì¶”ì¶œ"""
        try:
            # LocalFileAnalyzerì˜ LLM í˜¸ì¶œ ë©”ì„œë“œ í™œìš©
            # ì„ì‹œ í…ìŠ¤íŠ¸ì™€ íŒŒì¼ ì •ë³´ë¡œ í˜¸ì¶œ
            result = self.analyzer.analyze_document_structure_with_llm(
                text=prompt,
                file_path="kg_extraction.txt",
                file_extension=".txt",
                overrides={
                    **llm_config,
                    "enabled": True
                }
            )

            if not result.get("success"):
                return {"success": False, "error": result.get("error", "LLM í˜¸ì¶œ ì‹¤íŒ¨")}

            # LLM ì‘ë‹µ ì¶”ì¶œ
            analysis = result.get("analysis", {})
            response_text = json.dumps(analysis) if isinstance(analysis, dict) else str(analysis)

            return {"success": True, "response": response_text}

        except Exception as e:
            self.logger.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def _parse_kg_response(self, response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ Knowledge Graph êµ¬ì¡°ë¡œ íŒŒì‹±"""
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            kg_data = json.loads(response)

            # ê·¸ë˜í”„ êµ¬ì¡° ê²€ì¦
            if "graph" in kg_data:
                # Neo4j/Memgraph ìŠ¤íƒ€ì¼ (nodes, edges)
                return self._normalize_graph_structure(kg_data["graph"])
            elif "entities" in kg_data and "relationships" in kg_data:
                # ê¸°ì¡´ ìŠ¤íƒ€ì¼ (entities, relationships)
                return {
                    "nodes": kg_data.get("entities", []),
                    "edges": kg_data.get("relationships", [])
                }
            else:
                # ìµœìƒìœ„ ë ˆë²¨ì´ ì§ì ‘ ê·¸ë˜í”„ì¸ ê²½ìš°
                return kg_data

        except json.JSONDecodeError as e:
            self.logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ë°±ì—…: ì‘ë‹µì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            return self._extract_json_from_text(response)
        except Exception as e:
            self.logger.error(f"KG ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}", exc_info=True)
            return {"nodes": [], "edges": []}

    def _normalize_graph_structure(self, graph: Dict[str, Any]) -> Dict[str, Any]:
        """ê·¸ë˜í”„ êµ¬ì¡° ì •ê·œí™” (nodes, edges í˜•ì‹ìœ¼ë¡œ í†µì¼)"""
        return {
            "nodes": graph.get("nodes", graph.get("entities", [])),
            "edges": graph.get("edges", graph.get("relationships", []))
        }

    def _extract_json_from_text(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ"""
        import re

        # JSON ì½”ë“œ ë¸”ë¡ íŒ¨í„´ (```json ... ```)
        json_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
        match = re.search(json_block_pattern, text, re.DOTALL)

        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass

        # ì§ì ‘ { } ë¸”ë¡ ì°¾ê¸°
        brace_pattern = r'\{.*\}'
        match = re.search(brace_pattern, text, re.DOTALL)

        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass

        self.logger.warning("JSON ì¶”ì¶œ ì‹¤íŒ¨, ë¹ˆ ê·¸ë˜í”„ ë°˜í™˜")
        return {"nodes": [], "edges": []}

    def _enrich_kg_with_metadata(
        self,
        kg_data: Dict[str, Any],
        file_path: str,
        domain: str,
        structure_info: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Knowledge Graphì— ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        nodes = kg_data.get("nodes", [])
        edges = kg_data.get("edges", [])

        # í†µê³„ ê³„ì‚°
        entity_types = {}
        relationship_types = {}

        for node in nodes:
            node_type = node.get("type", "Unknown")
            entity_types[node_type] = entity_types.get(node_type, 0) + 1

        for edge in edges:
            edge_type = edge.get("type", "UNKNOWN")
            relationship_types[edge_type] = relationship_types.get(edge_type, 0) + 1

        # ê²°ê³¼ êµ¬ì¡° ìƒì„±
        result = {
            "success": True,
            "file_path": file_path,
            "domain": domain,
            "extraction_date": datetime.now().isoformat(),
            "graph": {
                "nodes": nodes,
                "edges": edges
            },
            "stats": {
                "entity_count": len(nodes),
                "relationship_count": len(edges),
                "entity_types": entity_types,
                "relationship_types": relationship_types,
                "density": self._calculate_graph_density(len(nodes), len(edges))
            },
            "metadata": {
                "source_document": Path(file_path).name,
                "domain": domain,
                "has_structure_info": structure_info is not None,
                "version": "1.0"
            }
        }

        return result

    def _calculate_graph_density(self, node_count: int, edge_count: int) -> float:
        """ê·¸ë˜í”„ ë°€ë„ ê³„ì‚° (0~1 ë²”ìœ„)"""
        if node_count <= 1:
            return 0.0
        max_possible_edges = node_count * (node_count - 1)  # ë°©í–¥ ê·¸ë˜í”„ ê¸°ì¤€
        return round(edge_count / max_possible_edges, 4) if max_possible_edges > 0 else 0.0

    def _create_error_result(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ê²°ê³¼ ìƒì„±"""
        return {
            "success": False,
            "error": error_message,
            "graph": {
                "nodes": [],
                "edges": []
            },
            "stats": {
                "entity_count": 0,
                "relationship_count": 0,
                "entity_types": {},
                "relationship_types": {},
                "density": 0.0
            }
        }

    def save_knowledge_graph(
        self,
        kg_result: Dict[str, Any],
        output_dir: Path,
        format: str = "json"
    ) -> Dict[str, str]:
        """
        Knowledge Graphë¥¼ íŒŒì¼ë¡œ ì €ì¥

        Args:
            kg_result: Knowledge Graph ê²°ê³¼
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            format: ì €ì¥ í˜•ì‹ (json, cypher, graphml)

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        saved_files = {}

        try:
            if format == "json" or format == "all":
                # JSON í˜•ì‹ ì €ì¥
                json_path = output_dir / "knowledge_graph.json"
                with json_path.open('w', encoding='utf-8') as f:
                    json.dump(kg_result, f, ensure_ascii=False, indent=2)
                saved_files["json"] = str(json_path)
                self.logger.info(f"ğŸ“ Knowledge Graph JSON ì €ì¥: {json_path}")

            if format == "cypher" or format == "all":
                # Cypher ì¿¼ë¦¬ í˜•ì‹ ì €ì¥
                cypher_path = output_dir / "knowledge_graph.cypher"
                cypher_content = self._generate_cypher_queries(kg_result)
                with cypher_path.open('w', encoding='utf-8') as f:
                    f.write(cypher_content)
                saved_files["cypher"] = str(cypher_path)
                self.logger.info(f"ğŸ“ Knowledge Graph Cypher ì €ì¥: {cypher_path}")

            if format == "graphml" or format == "all":
                # GraphML í˜•ì‹ ì €ì¥
                graphml_path = output_dir / "knowledge_graph.graphml"
                graphml_content = self._generate_graphml(kg_result)
                with graphml_path.open('w', encoding='utf-8') as f:
                    f.write(graphml_content)
                saved_files["graphml"] = str(graphml_path)
                self.logger.info(f"ğŸ“ Knowledge Graph GraphML ì €ì¥: {graphml_path}")

            return saved_files

        except Exception as e:
            self.logger.error(f"âŒ Knowledge Graph ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
            return saved_files

    def _generate_cypher_queries(self, kg_result: Dict[str, Any]) -> str:
        """Cypher CREATE ì¿¼ë¦¬ ìƒì„± (Neo4j/Memgraph í˜¸í™˜)"""
        queries = []
        queries.append("// Knowledge Graph Cypher Queries")
        queries.append(f"// Generated: {datetime.now().isoformat()}\n")

        # ë…¸ë“œ ìƒì„± ì¿¼ë¦¬
        queries.append("// Create Nodes")
        for node in kg_result.get("graph", {}).get("nodes", []):
            node_id = node.get("id", "")
            node_type = node.get("type", "Node")
            properties = node.get("properties", {})

            # í”„ë¡œí¼í‹° ë¬¸ìì—´ ìƒì„±
            props_str = ", ".join([
                f"{k}: {self._cypher_value(v)}"
                for k, v in properties.items()
            ])

            query = f"CREATE (n:{node_type} {{id: '{node_id}', {props_str}}});"
            queries.append(query)

        queries.append("\n// Create Relationships")
        for edge in kg_result.get("graph", {}).get("edges", []):
            source = edge.get("source", "")
            target = edge.get("target", "")
            edge_type = edge.get("type", "RELATED_TO")
            properties = edge.get("properties", {})

            # í”„ë¡œí¼í‹° ë¬¸ìì—´ ìƒì„±
            props_str = ", ".join([
                f"{k}: {self._cypher_value(v)}"
                for k, v in properties.items()
            ])

            query = (
                f"MATCH (a {{id: '{source}'}}), (b {{id: '{target}'}}) "
                f"CREATE (a)-[r:{edge_type} {{{props_str}}}]->(b);"
            )
            queries.append(query)

        return "\n".join(queries)

    def _cypher_value(self, value: Any) -> str:
        """Python ê°’ì„ Cypher ê°’ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if isinstance(value, str):
            # ë¬¸ìì—´ ì´ìŠ¤ì¼€ì´í”„
            escaped = value.replace("'", "\\'").replace('"', '\\"')
            return f"'{escaped}'"
        elif isinstance(value, bool):
            return "true" if value else "false"
        elif isinstance(value, (int, float)):
            return str(value)
        elif isinstance(value, list):
            items = [self._cypher_value(v) for v in value]
            return f"[{', '.join(items)}]"
        elif value is None:
            return "null"
        else:
            return f"'{str(value)}'"

    def _generate_graphml(self, kg_result: Dict[str, Any]) -> str:
        """GraphML XML í˜•ì‹ ìƒì„±"""
        lines = []
        lines.append('<?xml version="1.0" encoding="UTF-8"?>')
        lines.append('<graphml xmlns="http://graphml.graphdrawing.org/xmlns">')
        lines.append('  <graph id="KnowledgeGraph" edgedefault="directed">')

        # ë…¸ë“œ ì¶”ê°€
        for node in kg_result.get("graph", {}).get("nodes", []):
            node_id = node.get("id", "")
            node_type = node.get("type", "Node")
            lines.append(f'    <node id="{node_id}">')
            lines.append(f'      <data key="type">{node_type}</data>')

            # í”„ë¡œí¼í‹° ì¶”ê°€
            for key, value in node.get("properties", {}).items():
                lines.append(f'      <data key="{key}">{self._xml_escape(str(value))}</data>')

            lines.append('    </node>')

        # ì—£ì§€ ì¶”ê°€
        for idx, edge in enumerate(kg_result.get("graph", {}).get("edges", [])):
            edge_id = edge.get("id", f"e{idx}")
            source = edge.get("source", "")
            target = edge.get("target", "")
            edge_type = edge.get("type", "RELATED_TO")

            lines.append(f'    <edge id="{edge_id}" source="{source}" target="{target}">')
            lines.append(f'      <data key="type">{edge_type}</data>')

            # í”„ë¡œí¼í‹° ì¶”ê°€
            for key, value in edge.get("properties", {}).items():
                lines.append(f'      <data key="{key}">{self._xml_escape(str(value))}</data>')

            lines.append('    </edge>')

        lines.append('  </graph>')
        lines.append('</graphml>')

        return "\n".join(lines)

    def _xml_escape(self, text: str) -> str:
        """XML íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
        return (
            text.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
            .replace('"', "&quot;")
            .replace("'", "&apos;")
        )
