"""
íŒŒì„œë³„ ê°œë³„ íŒŒì¼ ì €ì¥ ê´€ë¦¬ì

ì´ ëª¨ë“ˆì€ ê° íŒŒì„œì˜ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- íŒŒì„œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼
- ë¬¸ì„œ êµ¬ì¡°í™” ì •ë³´ (ì¥, ì ˆ, ë¬¸ë‹¨ ë“±)
- ë©”íƒ€ë°ì´í„° ì •ë³´ (í‚¤ì›Œë“œ, ìš”ì•½, ì£¼ì œ ë“±)
"""

import json
import logging
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class DocumentStructure:
    """ë¬¸ì„œ êµ¬ì¡° ì •ë³´"""
    sections: List[Dict[str, Any]] = None  # ì¥/ì ˆ êµ¬ì¡°
    headings: List[Dict[str, Any]] = None  # ì œëª© ê³„ì¸µ
    paragraphs: List[Dict[str, Any]] = None  # ë¬¸ë‹¨ ì •ë³´
    tables: List[Dict[str, Any]] = None  # í…Œì´ë¸” ì •ë³´
    lists: List[Dict[str, Any]] = None  # ë¦¬ìŠ¤íŠ¸ ì •ë³´
    figures: List[Dict[str, Any]] = None  # ê·¸ë¦¼/ì´ë¯¸ì§€ ì •ë³´
    
    def __post_init__(self):
        if self.sections is None:
            self.sections = []
        if self.headings is None:
            self.headings = []
        if self.paragraphs is None:
            self.paragraphs = []
        if self.tables is None:
            self.tables = []
        if self.lists is None:
            self.lists = []
        if self.figures is None:
            self.figures = []


@dataclass
class ParserMetadata:
    """íŒŒì„œë³„ ë©”íƒ€ë°ì´í„°"""
    keywords: List[str] = None
    summary: Dict[str, str] = None  # intro, conclusion, core, tone
    topics: List[str] = None
    language: str = None
    document_type: str = None
    formality: str = None
    target_audience: str = None
    
    def __post_init__(self):
        if self.keywords is None:
            self.keywords = []
        if self.summary is None:
            self.summary = {}
        if self.topics is None:
            self.topics = []


class ParserFileManager:
    """íŒŒì„œë³„ íŒŒì¼ ì €ì¥ ê´€ë¦¬ì"""
    
    def __init__(self, base_output_dir: str = "tests/outputs"):
        """
        Args:
            base_output_dir: ì¶œë ¥ íŒŒì¼ë“¤ì„ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬
        """
        self.base_output_dir = Path(base_output_dir)
        self.base_output_dir.mkdir(exist_ok=True)
        
    def _generate_session_id(self, file_path: str, parser_name: str) -> str:
        """ì„¸ì…˜ ID ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_hash = hashlib.md5(file_path.encode()).hexdigest()[:8]
        return f"{timestamp}_{parser_name}_{file_hash}"
    
    def _create_parser_directory(self, file_path: str, parser_name: str) -> Path:
        """íŒŒì„œë³„ ë””ë ‰í† ë¦¬ ìƒì„±"""
        session_id = self._generate_session_id(file_path, parser_name)
        parser_dir = self.base_output_dir / session_id
        parser_dir.mkdir(exist_ok=True)
        return parser_dir
    
    def save_parser_text(self, file_path: str, parser_name: str, extracted_text: str) -> Path:
        """íŒŒì„œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ ì €ì¥"""
        parser_dir = self._create_parser_directory(file_path, parser_name)
        text_file = parser_dir / f"{parser_name}_extracted_text.txt"
        
        try:
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write(f"# {parser_name} íŒŒì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼\n")
                f.write(f"# ì›ë³¸ íŒŒì¼: {file_path}\n")
                f.write(f"# ì¶”ì¶œ ì‹œê°: {datetime.now().isoformat()}\n")
                f.write(f"# í…ìŠ¤íŠ¸ ê¸¸ì´: {len(extracted_text)} ë¬¸ì\n\n")
                f.write(extracted_text)
            
            logger.info(f"âœ… {parser_name} í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {text_file}")
            return text_file
            
        except Exception as e:
            logger.error(f"âŒ {parser_name} í…ìŠ¤íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_document_structure(self, file_path: str, parser_name: str, 
                              structure: DocumentStructure, raw_structure: Dict = None) -> Path:
        """ë¬¸ì„œ êµ¬ì¡° ì •ë³´ ì €ì¥"""
        parser_dir = self._create_parser_directory(file_path, parser_name)
        structure_file = parser_dir / f"{parser_name}_document_structure.json"
        
        try:
            structure_data = {
                "@context": "http://purl.org/dc/terms/",
                "parser_name": parser_name,
                "source_file": file_path,
                "extraction_timestamp": datetime.now().isoformat(),
                "document_structure": {
                    "sections": structure.sections,
                    "headings": structure.headings,
                    "paragraphs": structure.paragraphs,
                    "tables": structure.tables,
                    "lists": structure.lists,
                    "figures": structure.figures,
                    "statistics": {
                        "total_sections": len(structure.sections),
                        "total_headings": len(structure.headings),
                        "total_paragraphs": len(structure.paragraphs),
                        "total_tables": len(structure.tables),
                        "total_lists": len(structure.lists),
                        "total_figures": len(structure.figures)
                    }
                }
            }
            
            # ì›ë³¸ êµ¬ì¡° ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
            if raw_structure:
                structure_data["raw_parser_structure"] = raw_structure
            
            with open(structure_file, 'w', encoding='utf-8') as f:
                json.dump(structure_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… {parser_name} ë¬¸ì„œ êµ¬ì¡° ì €ì¥ ì™„ë£Œ: {structure_file}")
            return structure_file
            
        except Exception as e:
            logger.error(f"âŒ {parser_name} ë¬¸ì„œ êµ¬ì¡° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_parser_metadata(self, file_path: str, parser_name: str, 
                           metadata: ParserMetadata, raw_metadata: Dict = None) -> Path:
        """íŒŒì„œë³„ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        parser_dir = self._create_parser_directory(file_path, parser_name)
        metadata_file = parser_dir / f"{parser_name}_metadata.json"
        
        try:
            metadata_data = {
                "@context": "http://purl.org/dc/terms/",
                "parser_name": parser_name,
                "source_file": file_path,
                "extraction_timestamp": datetime.now().isoformat(),
                "extracted_metadata": {
                    "keywords": metadata.keywords,
                    "summary": metadata.summary,
                    "topics": metadata.topics,
                    "language": metadata.language,
                    "document_type": metadata.document_type,
                    "formality": metadata.formality,
                    "target_audience": metadata.target_audience,
                    "statistics": {
                        "keywords_count": len(metadata.keywords),
                        "topics_count": len(metadata.topics),
                        "summary_fields": list(metadata.summary.keys()) if metadata.summary else []
                    }
                }
            }
            
            # ì›ë³¸ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ í¬í•¨
            if raw_metadata:
                metadata_data["raw_parser_metadata"] = raw_metadata
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… {parser_name} ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_file}")
            return metadata_file
            
        except Exception as e:
            logger.error(f"âŒ {parser_name} ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def save_complete_parser_result(self, file_path: str, parser_name: str,
                                  extracted_text: str, structure: DocumentStructure,
                                  metadata: ParserMetadata, raw_data: Dict = None) -> Dict[str, Path]:
        """íŒŒì„œì˜ ì „ì²´ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            saved_files = {}
            
            # 1. í…ìŠ¤íŠ¸ ì €ì¥
            saved_files['text'] = self.save_parser_text(file_path, parser_name, extracted_text)
            
            # 2. êµ¬ì¡° ì •ë³´ ì €ì¥
            raw_structure = raw_data.get('structure') if raw_data else None
            saved_files['structure'] = self.save_document_structure(
                file_path, parser_name, structure, raw_structure
            )
            
            # 3. ë©”íƒ€ë°ì´í„° ì €ì¥
            raw_metadata = raw_data.get('metadata') if raw_data else None
            saved_files['metadata'] = self.save_parser_metadata(
                file_path, parser_name, metadata, raw_metadata
            )
            
            # 4. í†µí•© ì •ë³´ íŒŒì¼ ì €ì¥
            parser_dir = self._create_parser_directory(file_path, parser_name)
            summary_file = parser_dir / f"{parser_name}_summary.json"
            
            summary_data = {
                "@context": "http://purl.org/dc/terms/",
                "parser_name": parser_name,
                "source_file": file_path,
                "extraction_timestamp": datetime.now().isoformat(),
                "saved_files": {k: str(v) for k, v in saved_files.items()},
                "processing_summary": {
                    "text_length": len(extracted_text),
                    "structure_elements": len(structure.sections) + len(structure.headings),
                    "metadata_keywords": len(metadata.keywords),
                    "parser_success": True
                }
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            
            saved_files['summary'] = summary_file
            
            logger.info(f"ğŸ‰ {parser_name} ì „ì²´ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {parser_dir}")
            return saved_files
            
        except Exception as e:
            logger.error(f"âŒ {parser_name} ì „ì²´ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_structure_from_docling(self, docling_result: Dict) -> DocumentStructure:
        """Docling íŒŒì„œ ê²°ê³¼ì—ì„œ ë¬¸ì„œ êµ¬ì¡° ì¶”ì¶œ"""
        structure = DocumentStructure()
        
        try:
            # Docling êµ¬ì¡° ì •ë³´ ì¶”ì¶œ
            if 'docling_structure' in docling_result:
                docling_struct = docling_result['docling_structure']
                structure.sections = docling_struct.get('sections', [])
                
            if 'document_structure' in docling_result:
                doc_struct = docling_result['document_structure']
                structure.headings = doc_struct.get('sections', [])
                structure.tables = [{'count': doc_struct.get('tables_count', 0)}]
                structure.figures = [{'count': doc_struct.get('figures_count', 0)}]
                
        except Exception as e:
            logger.warning(f"Docling êµ¬ì¡° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return structure
    
    def extract_metadata_from_result(self, result: Dict) -> ParserMetadata:
        """ê²°ê³¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = ParserMetadata()
        
        try:
            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            if 'keywords' in result:
                metadata.keywords = result['keywords'] if isinstance(result['keywords'], list) else []
                
            if 'content_analysis' in result:
                analysis = result['content_analysis']
                metadata.summary = {
                    'core': analysis.get('summary', ''),
                    'topics': analysis.get('main_topics', [])
                }
                metadata.topics = analysis.get('keywords', [])
                
            metadata.language = result.get('dc:language', result.get('language', 'ko'))
            metadata.document_type = result.get('document_type', 'ë¬¸ì„œ')
            
        except Exception as e:
            logger.warning(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
        return metadata


# ì „ì—­ íŒŒì¼ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
file_manager = ParserFileManager()


def save_parser_results(file_path: str, parser_results: Dict[str, Dict]) -> Dict[str, Dict[str, Path]]:
    """ëª¨ë“  íŒŒì„œ ê²°ê³¼ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    saved_results = {}
    
    for parser_name, result_data in parser_results.items():
        try:
            if not result_data.get('success', False):
                logger.warning(f"â­ï¸  {parser_name} íŒŒì„œ ì‹¤íŒ¨ë¡œ ì €ì¥ ê±´ë„ˆëœ€")
                continue
                
            result = result_data.get('metadata', {})
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = result.get('content_analysis', {}).get('text', 
                                      result.get('text', 'ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì—†ìŒ'))
            
            # êµ¬ì¡° ì •ë³´ ì¶”ì¶œ
            if parser_name == 'docling':
                structure = file_manager.extract_structure_from_docling(result)
            else:
                structure = DocumentStructure()  # ê¸°ë³¸ ë¹ˆ êµ¬ì¡°
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = file_manager.extract_metadata_from_result(result)
            
            # ì „ì²´ ê²°ê³¼ ì €ì¥
            saved_files = file_manager.save_complete_parser_result(
                file_path, parser_name, extracted_text, structure, metadata, 
                raw_data={'structure': result, 'metadata': result}
            )
            
            saved_results[parser_name] = saved_files
            
        except Exception as e:
            logger.error(f"âŒ {parser_name} ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            continue
    
    logger.info(f"ğŸ“ ì´ {len(saved_results)}ê°œ íŒŒì„œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    return saved_results