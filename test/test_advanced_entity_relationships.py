#!/usr/bin/env python3
"""
ê³ ê¸‰ ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ êµ¬ì¡° ë¶„ì„ í¬í•¨)

ì‚¬ìš©ë²•:
cd /Users/selmo/Workspaces/DocExtract
PYTHONPATH=backend python test/test_advanced_entity_relationships.py
"""

import sys
import os
import json
from pathlib import Path

# ë°±ì—”ë“œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

from services.hierarchical_kg_builder import HierarchicalKGBuilder

def create_mock_structure_analysis():
    """ëª¨ì˜ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ ìƒì„±"""
    return {
        "structure_elements": {
            "sections": [
                {
                    "title": "ê¸°ìˆ  ìŠ¤íƒ",
                    "level": 2,
                    "content": "FastAPI: ê³ ì„±ëŠ¥ Python ì›¹ í”„ë ˆì„ì›Œí¬\nSQLAlchemy: ë°ì´í„°ë² ì´ìŠ¤ ORM\nPydantic: ë°ì´í„° ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬"
                },
                {
                    "title": "ë°ì´í„°ë² ì´ìŠ¤", 
                    "level": 2,
                    "content": "PostgreSQL: ë©”ì¸ DB, ACID ì¤€ìˆ˜, í™•ì¥ì„±\nRedis: ìºì‹±, ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥\nElasticsearch: ê²€ìƒ‰, ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„"
                }
            ],
            "tables": [
                {
                    "content": "| ë°ì´í„°ë² ì´ìŠ¤ | ìš©ë„ | ì¥ì  |\n|-------------|------|------|\n| PostgreSQL  | ë©”ì¸ DB | ACID ì¤€ìˆ˜, í™•ì¥ì„± |\n| Redis       | ìºì‹± | ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥ |\n| Elasticsearch | ê²€ìƒ‰ | ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„ |",
                    "page": 1,
                    "rows": [
                        ["ë°ì´í„°ë² ì´ìŠ¤", "ìš©ë„", "ì¥ì "],
                        ["PostgreSQL", "ë©”ì¸ DB", "ACID ì¤€ìˆ˜, í™•ì¥ì„±"],
                        ["Redis", "ìºì‹±", "ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥"],
                        ["Elasticsearch", "ê²€ìƒ‰", "ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„"]
                    ]
                }
            ]
        },
        "summary": {
            "best_parser": "base_parser"
        }
    }

def create_mock_parsing_results():
    """ëª¨ì˜ íŒŒì‹± ê²°ê³¼ ìƒì„±"""
    return {
        "parsing_results": {
            "base_parser": {
                "structured_info": {
                    "document_structure": {
                        "sections": [
                            {
                                "title": "ê¸°ìˆ  ìŠ¤íƒ",
                                "level": 2,
                                "line": 7,
                                "content": "FastAPI: ê³ ì„±ëŠ¥ Python ì›¹ í”„ë ˆì„ì›Œí¬\nSQLAlchemy: ë°ì´í„°ë² ì´ìŠ¤ ORM\nPydantic: ë°ì´í„° ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬"
                            },
                            {
                                "title": "ë°ì´í„°ë² ì´ìŠ¤",
                                "level": 2, 
                                "line": 15,
                                "content": "PostgreSQL: ë©”ì¸ DB, ACID ì¤€ìˆ˜, í™•ì¥ì„±\nRedis: ìºì‹±, ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥\nElasticsearch: ê²€ìƒ‰, ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„"
                            }
                        ],
                        "tables": [
                            {
                                "content": "| ë°ì´í„°ë² ì´ìŠ¤ | ìš©ë„ | ì¥ì  |\n|-------------|------|------|\n| PostgreSQL  | ë©”ì¸ DB | ACID ì¤€ìˆ˜, í™•ì¥ì„± |\n| Redis       | ìºì‹± | ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥ |\n| Elasticsearch | ê²€ìƒ‰ | ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„ |",
                                "page": 1,
                                "rows": [
                                    ["ë°ì´í„°ë² ì´ìŠ¤", "ìš©ë„", "ì¥ì "],
                                    ["PostgreSQL", "ë©”ì¸ DB", "ACID ì¤€ìˆ˜, í™•ì¥ì„±"],
                                    ["Redis", "ìºì‹±", "ê³ ì† ì¸ë©”ëª¨ë¦¬ ì €ì¥"], 
                                    ["Elasticsearch", "ê²€ìƒ‰", "ì „ë¬¸ ê²€ìƒ‰ ì—”ì§„"]
                                ],
                                "columns": ["ë°ì´í„°ë² ì´ìŠ¤", "ìš©ë„", "ì¥ì "]
                            }
                        ]
                    }
                }
            }
        },
        "summary": {
            "best_parser": "base_parser"
        }
    }

def test_advanced_entity_relationships():
    """ê³ ê¸‰ ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ê²½ë¡œ
    test_doc_path = "test/hierarchical_kg_test_document.md"
    
    print("ğŸ§ª ê³ ê¸‰ ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: {test_doc_path}")
    
    # ë¬¸ì„œ ì½ê¸°
    try:
        with open(test_doc_path, 'r', encoding='utf-8') as f:
            document_text = f.read()
    except FileNotFoundError:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_doc_path}")
        return
    
    # êµ¬ì¡°ë³„ë¡œ ë¶„ì‚°ëœ í‚¤ì›Œë“œ ë°ì´í„° ìƒì„±
    mock_keywords = {
        "llm": [
            # ê¸°ìˆ  ìŠ¤íƒ ì„¹ì…˜ì—ì„œ ë°œê²¬ë  í‚¤ì›Œë“œë“¤
            {"keyword": "FastAPI", "score": 0.95, "category": "technology", "start_position": 300, "end_position": 307},
            {"keyword": "SQLAlchemy", "score": 0.88, "category": "framework", "start_position": 350, "end_position": 360},
            {"keyword": "Pydantic", "score": 0.85, "category": "framework", "start_position": 380, "end_position": 388},
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì„¹ì…˜ì—ì„œ ë°œê²¬ë  í‚¤ì›Œë“œë“¤  
            {"keyword": "PostgreSQL", "score": 0.92, "category": "database", "start_position": 500, "end_position": 510},
            {"keyword": "Redis", "score": 0.87, "category": "database", "start_position": 550, "end_position": 555},
            {"keyword": "Elasticsearch", "score": 0.82, "category": "database", "start_position": 600, "end_position": 613},
            
            # ê³µí†µ ê°œë…ë“¤
            {"keyword": "RESTful", "score": 0.90, "category": "concept"},
            {"keyword": "API", "score": 0.93, "category": "concept"},
            {"keyword": "ORM", "score": 0.89, "category": "concept"}
        ]
    }
    
    # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
    metadata = {
        "name": "hierarchical_kg_test_document.md",
        "size": len(document_text),
        "extension": ".md"
    }
    
    # ëª¨ì˜ êµ¬ì¡° ë¶„ì„ê³¼ íŒŒì‹± ê²°ê³¼ ìƒì„±
    structure_analysis = create_mock_structure_analysis()
    parsing_results = create_mock_parsing_results()
    
    # ê³„ì¸µì  KG ë¹Œë” ìƒì„± (Memgraph ë¹„í™œì„±í™”)
    kg_builder = HierarchicalKGBuilder(auto_save_to_memgraph=False)
    
    print("ğŸ—ï¸ ê³„ì¸µì  KG êµ¬ì¶• ì¤‘... (êµ¬ì¡° ë¶„ì„ í¬í•¨)")
    
    # KG êµ¬ì¶•
    result = kg_builder.build_hierarchical_knowledge_graph(
        file_path=test_doc_path,
        document_text=document_text,
        keywords=mock_keywords,
        metadata=metadata,
        structure_analysis=structure_analysis,
        parsing_results=parsing_results,
        force_rebuild=True
    )
    
    print(f"âœ… KG êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ì—”í‹°í‹°: {len(result['entities'])}ê°œ")
    print(f"ğŸ”— ì´ ê´€ê³„: {len(result['relationships'])}ê°œ")
    
    # ì—”í‹°í‹° ë¶„ì„
    document_entities = [e for e in result["entities"] if e["type"] == "Document"]
    structure_entities = [e for e in result["entities"] if e.get("properties", {}).get("structural_element")]
    keyword_entities = [e for e in result["entities"] if e.get("properties", {}).get("hierarchical_entity")]
    
    print(f"\nğŸ“ˆ ì—”í‹°í‹° ë¶„í¬:")
    print(f"  - ë¬¸ì„œ ì—”í‹°í‹°: {len(document_entities)}ê°œ")
    print(f"  - êµ¬ì¡° ì—”í‹°í‹°: {len(structure_entities)}ê°œ") 
    print(f"  - í‚¤ì›Œë“œ ì—”í‹°í‹°: {len(keyword_entities)}ê°œ")
    
    # ê´€ê³„ ìœ í˜•ë³„ ë¶„ì„
    relationship_types = {}
    structure_relationships = []
    entity_relationships = []
    
    for rel in result["relationships"]:
        rel_name = rel.get("properties", {}).get("relationship_name", "UNKNOWN")
        relationship_types[rel_name] = relationship_types.get(rel_name, 0) + 1
        
        # êµ¬ì¡° ê´€ê³„ vs ì—”í‹°í‹° ê´€ê³„ ë¶„ë¥˜
        if rel["type"] == "CONTAINS_STRUCTURE":
            structure_relationships.append(rel)
        elif rel.get("properties", {}).get("entity_to_entity"):
            entity_relationships.append(rel)
    
    print(f"\nğŸ”— ê´€ê³„ ìœ í˜• ë¶„í¬:")
    for rel_type, count in sorted(relationship_types.items()):
        print(f"  - {rel_type}: {count}ê°œ")
    
    print(f"\nğŸ¯ ê´€ê³„ ì¹´í…Œê³ ë¦¬:")
    print(f"  - êµ¬ì¡° ê´€ê³„: {len(structure_relationships)}ê°œ")
    print(f"  - ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„: {len(entity_relationships)}ê°œ")
    
    if entity_relationships:
        print(f"\nğŸ” ì—”í‹°í‹° ê°„ ê´€ê³„ ìƒì„¸ (ìƒìœ„ 15ê°œ):")
        
        # ì—”í‹°í‹° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë§¤í•‘
        entity_text_map = {}
        entity_type_map = {}
        for entity in result["entities"]:
            if entity.get("properties", {}).get("hierarchical_entity"):
                entity_text_map[entity["id"]] = entity.get("properties", {}).get("text", entity["id"])
                entity_type_map[entity["id"]] = entity.get("type", "Unknown")
        
        # ê´€ê³„ë¥¼ ì‹ ë¢°ë„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_relationships = sorted(entity_relationships, 
                                    key=lambda x: x.get("properties", {}).get("confidence_score", 0),
                                    reverse=True)
        
        for i, rel in enumerate(sorted_relationships[:15], 1):
            source_text = entity_text_map.get(rel["source"], rel["source"])
            target_text = entity_text_map.get(rel["target"], rel["target"])
            source_type = entity_type_map.get(rel["source"], "Unknown")
            target_type = entity_type_map.get(rel["target"], "Unknown")
            rel_name = rel.get("properties", {}).get("relationship_name", "UNKNOWN")
            confidence = rel.get("properties", {}).get("confidence_score", 0)
            extraction_method = rel.get("properties", {}).get("extraction_method", "unknown")
            
            print(f"  {i:2d}. {source_text} ({source_type}) --[{rel_name}]--> {target_text} ({target_type})")
            print(f"      ì‹ ë¢°ë„: {confidence:.2f}, ì¶”ì¶œë°©ë²•: {extraction_method}")
            
            if rel.get("properties", {}).get("pattern_based"):
                print(f"      íŒ¨í„´ ê¸°ë°˜: âœ…")
            if rel.get("properties", {}).get("llm_extracted"):
                print(f"      LLM ì¶”ì¶œ: âœ…")
            
            if rel.get("properties", {}).get("context_snippet"):
                context = rel["properties"]["context_snippet"][:80]
                print(f"      ì»¨í…ìŠ¤íŠ¸: \"{context}...\"")
            print()
    
    # êµ¬ì¡°ë³„ ì—”í‹°í‹° ë¶„í¬ ë¶„ì„
    structure_entity_distribution = {}
    for entity in keyword_entities:
        source_structure = entity.get("properties", {}).get("source_structure", "unknown")
        if source_structure not in structure_entity_distribution:
            structure_entity_distribution[source_structure] = []
        structure_entity_distribution[source_structure].append(entity.get("properties", {}).get("text", ""))
    
    print(f"\nğŸ“Š êµ¬ì¡°ë³„ ì—”í‹°í‹° ë¶„í¬:")
    for structure_id, entities in structure_entity_distribution.items():
        # êµ¬ì¡° ì´ë¦„ ì°¾ê¸°
        structure_name = "Unknown"
        for struct_entity in structure_entities:
            if struct_entity["id"] == structure_id:
                structure_name = struct_entity.get("properties", {}).get("title", structure_id)
                break
        
        print(f"  - {structure_name}: {len(entities)}ê°œ ì—”í‹°í‹°")
        print(f"    {', '.join(entities[:5])}{'...' if len(entities) > 5 else ''}")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    output_file = "test/advanced_entity_relationships_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
    success = len(entity_relationships) > 0
    if success:
        print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  í…ŒìŠ¤íŠ¸ ì£¼ì˜: ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„ê°€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    return success

if __name__ == "__main__":
    test_advanced_entity_relationships()