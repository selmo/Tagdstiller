"""
Memgraph Database Service - KG ë°ì´í„° ê´€ë¦¬

Memgraph ë°ì´í„°ë² ì´ìŠ¤ì™€ì˜ ì—°ê²°, ë°ì´í„° ì‚½ì…, ì¡°íšŒ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ë„ë©”ì¸ë³„ KG ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ Memgraphì— ì €ì¥í•˜ê³  Cypher ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import logging
from typing import Dict, List, Any, Optional, Tuple
import json
import time
from pathlib import Path

try:
    from neo4j import GraphDatabase, Driver
    NEO4J_AVAILABLE = True
except ImportError:
    NEO4J_AVAILABLE = False
    print("Warning: neo4j driver not available. Install with: pip install neo4j")


class MemgraphService:
    """Memgraph ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤"""
    
    def __init__(self, uri: str = "bolt://localhost:7687", username: str = "", password: str = ""):
        """
        Memgraph ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            uri: Memgraph ì—°ê²° URI (ê¸°ë³¸: bolt://localhost:7687)
            username: ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: ë¹ˆ ë¬¸ìì—´)
            password: ë¹„ë°€ë²ˆí˜¸ (ê¸°ë³¸ê°’: ë¹ˆ ë¬¸ìì—´)
        """
        self.uri = uri
        self.username = username
        self.password = password
        self.driver: Optional[Driver] = None
        self.logger = logging.getLogger(__name__)
        
        if not NEO4J_AVAILABLE:
            self.logger.error("neo4j driverê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. 'pip install neo4j' ì‹¤í–‰ í•„ìš”")
            return
        
        self.connect()
    
    def connect(self) -> bool:
        """Memgraphì— ì—°ê²°"""
        if not NEO4J_AVAILABLE:
            return False
            
        try:
            self.logger.info(f"Memgraph ì—°ê²° ì‹œë„: {self.uri}")
            self.driver = GraphDatabase.driver(self.uri, auth=(self.username, self.password))
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with self.driver.session() as session:
                result = session.run("RETURN 'Memgraph ì—°ê²° ì„±ê³µ' as message")
                message = result.single()["message"]
                self.logger.info(f"âœ… {message}")
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ Memgraph ì—°ê²° ì‹¤íŒ¨: {e}")
            if self.driver:
                self.driver.close()
                self.driver = None
            return False
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.driver:
            self.driver.close()
            self.driver = None
            self.logger.info("Memgraph ì—°ê²° ì¢…ë£Œ")
    
    def is_connected(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        if not self.driver:
            return False
        try:
            with self.driver.session() as session:
                session.run("RETURN 1")
            return True
        except Exception:
            return False
    
    def execute_query(self, query: str, parameters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """Cypher ì¿¼ë¦¬ ì‹¤í–‰"""
        if not self.is_connected():
            self.logger.error("Memgraphì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return []
        
        try:
            with self.driver.session() as session:
                result = session.run(query, parameters or {})
                return [record.data() for record in result]
        except Exception as e:
            self.logger.error(f"ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {query[:100]}... ì˜¤ë¥˜: {e}")
            return []
    
    def clear_database(self, confirm: bool = False) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì‚­ì œ (ì£¼ì˜!)"""
        if not confirm:
            self.logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œì—ëŠ” confirm=True í•„ìš”")
            return False
        
        try:
            self.logger.warning("ğŸ—‘ï¸ Memgraph ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì‚­ì œ ì¤‘...")
            result = self.execute_query("MATCH (n) DETACH DELETE n")
            self.logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì™„ë£Œ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def insert_kg_data(self, kg_data: Dict[str, Any], clear_existing: bool = False) -> bool:
        """KG ë°ì´í„°ë¥¼ Memgraphì— ì‚½ì…"""
        if not self.is_connected():
            self.logger.error("Memgraphì— ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return False
        
        try:
            start_time = time.time()
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì˜µì…˜)
            if clear_existing:
                file_path = kg_data.get("metadata", {}).get("file_path")
                if file_path:
                    self._clear_document_data(file_path)
            
            # ì—”í‹°í‹° ì‚½ì…
            entities_inserted = self._insert_entities(kg_data.get("entities", []))
            
            # ê´€ê³„ ì‚½ì…
            relationships_inserted = self._insert_relationships(kg_data.get("relationships", []))
            
            # ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
            self._create_indexes()
            
            elapsed_time = time.time() - start_time
            self.logger.info(
                f"âœ… KG ë°ì´í„° ì‚½ì… ì™„ë£Œ - "
                f"ì—”í‹°í‹°: {entities_inserted}ê°œ, ê´€ê³„: {relationships_inserted}ê°œ, "
                f"ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ"
            )
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ KG ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
            return False
    
    def _clear_document_data(self, file_path: str):
        """íŠ¹ì • ë¬¸ì„œì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ"""
        import hashlib
        doc_id = hashlib.sha1(str(file_path).encode("utf-8")).hexdigest()[:16]
        
        query = """
        MATCH (doc:Document {id: $doc_id})
        OPTIONAL MATCH (doc)-[r]-()
        DETACH DELETE doc, r
        """
        
        self.execute_query(query, {"doc_id": doc_id})
        self.logger.info(f"ğŸ—‘ï¸ ë¬¸ì„œ '{file_path}' ê¸°ì¡´ ë°ì´í„° ì‚­ì œ")
    
    def _insert_entities(self, entities: List[Dict[str, Any]]) -> int:
        """ì—”í‹°í‹° ë°°ì¹˜ ì‚½ì…"""
        if not entities:
            return 0
        
        # ì—”í‹°í‹° íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
        entities_by_type = {}
        for entity in entities:
            entity_type = entity.get("type", "Unknown")
            if entity_type not in entities_by_type:
                entities_by_type[entity_type] = []
            entities_by_type[entity_type].append(entity)
        
        total_inserted = 0
        
        # ê° íƒ€ì…ë³„ë¡œ ë°°ì¹˜ ì‚½ì…
        for entity_type, type_entities in entities_by_type.items():
            query = f"""
            UNWIND $entities AS entity
            MERGE (n:{entity_type} {{id: entity.id}})
            SET n += entity.properties
            """
            
            # propertiesì—ì„œ ë³µì¡í•œ ê°ì²´ëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            processed_entities = []
            for entity in type_entities:
                processed_entity = {
                    "id": entity["id"],
                    "properties": self._serialize_properties(entity.get("properties", {}))
                }
                processed_entities.append(processed_entity)
            
            self.execute_query(query, {"entities": processed_entities})
            total_inserted += len(type_entities)
            
            self.logger.debug(f"  ğŸ“ {entity_type}: {len(type_entities)}ê°œ ì—”í‹°í‹° ì‚½ì…")
        
        return total_inserted
    
    def _insert_relationships(self, relationships: List[Dict[str, Any]]) -> int:
        """ê´€ê³„ ë°°ì¹˜ ì‚½ì…"""
        if not relationships:
            return 0
        
        # ê´€ê³„ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
        relationships_by_type = {}
        for rel in relationships:
            rel_type = rel.get("type", "RELATED_TO")
            if rel_type not in relationships_by_type:
                relationships_by_type[rel_type] = []
            relationships_by_type[rel_type].append(rel)
        
        total_inserted = 0
        
        # ê° íƒ€ì…ë³„ë¡œ ë°°ì¹˜ ì‚½ì…
        for rel_type, type_relationships in relationships_by_type.items():
            # Cypherì—ì„œ ì•ˆì „í•œ ê´€ê³„ íƒ€ì…ëª…ìœ¼ë¡œ ë³€í™˜
            safe_rel_type = rel_type.replace("-", "_").replace(" ", "_")
            
            query = f"""
            UNWIND $relationships AS rel
            MATCH (source {{id: rel.source}})
            MATCH (target {{id: rel.target}})
            MERGE (source)-[r:{safe_rel_type}]->(target)
            SET r += rel.properties
            """
            
            # properties ì§ë ¬í™”
            processed_relationships = []
            for rel in type_relationships:
                processed_rel = {
                    "source": rel["source"],
                    "target": rel["target"],
                    "properties": self._serialize_properties(rel.get("properties", {}))
                }
                processed_relationships.append(processed_rel)
            
            self.execute_query(query, {"relationships": processed_relationships})
            total_inserted += len(type_relationships)
            
            self.logger.debug(f"  ğŸ”— {rel_type}: {len(type_relationships)}ê°œ ê´€ê³„ ì‚½ì…")
        
        return total_inserted
    
    def _serialize_properties(self, properties: Dict[str, Any]) -> Dict[str, Any]:
        """ë³µì¡í•œ ì†ì„±ì„ ì§ë ¬í™”"""
        serialized = {}
        for key, value in properties.items():
            if isinstance(value, (list, dict, set)):
                # ë³µì¡í•œ ê°ì²´ëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
                serialized[key] = json.dumps(value, ensure_ascii=False, default=str)
            elif value is None:
                # None ê°’ì€ ìƒëµ
                continue
            else:
                serialized[key] = value
        return serialized
    
    def _create_indexes(self):
        """ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ìƒì„±"""
        indexes = [
            "CREATE INDEX ON :Document(id)",
            "CREATE INDEX ON :Document(path)",
            "CREATE INDEX ON :Keyword(text)",
            "CREATE INDEX ON :Technology(name)",
            "CREATE INDEX ON :Author(name)",
            "CREATE INDEX ON :Company(name)"
        ]
        
        for index_query in indexes:
            try:
                self.execute_query(index_query)
            except Exception:
                # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
    
    def get_document_kg(self, file_path: str) -> Dict[str, Any]:
        """íŠ¹ì • ë¬¸ì„œì˜ KG ë°ì´í„° ì¡°íšŒ"""
        import hashlib
        doc_id = hashlib.sha1(str(file_path).encode("utf-8")).hexdigest()[:16]
        
        # ë¬¸ì„œì™€ ì—°ê²°ëœ ëª¨ë“  ì—”í‹°í‹° ë° ê´€ê³„ ì¡°íšŒ
        query = """
        MATCH (doc:Document {id: $doc_id})
        OPTIONAL MATCH (doc)-[r]->(related)
        RETURN doc, r, related
        """
        
        results = self.execute_query(query, {"doc_id": doc_id})
        
        if not results:
            return {"entities": [], "relationships": [], "message": "ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"}
        
        # ê²°ê³¼ë¥¼ KG í˜•íƒœë¡œ ë³€í™˜
        entities = []
        relationships = []
        entity_ids = set()
        
        for record in results:
            doc_data = record.get("doc")
            rel_data = record.get("r") 
            related_data = record.get("related")
            
            # ë¬¸ì„œ ì—”í‹°í‹° ì¶”ê°€
            if doc_data and doc_data["id"] not in entity_ids:
                entities.append({
                    "id": doc_data["id"],
                    "type": "Document",
                    "properties": doc_data
                })
                entity_ids.add(doc_data["id"])
            
            # ì—°ê²°ëœ ì—”í‹°í‹° ì¶”ê°€
            if related_data and related_data["id"] not in entity_ids:
                # ì—”í‹°í‹° íƒ€ì…ì€ ë¼ë²¨ì—ì„œ ì¶”ì¶œ
                entity_type = "Unknown"
                if hasattr(related_data, 'labels') and related_data.labels:
                    entity_type = list(related_data.labels)[0]
                
                entities.append({
                    "id": related_data["id"],
                    "type": entity_type,
                    "properties": related_data
                })
                entity_ids.add(related_data["id"])
            
            # ê´€ê³„ ì¶”ê°€
            if rel_data and doc_data and related_data:
                relationships.append({
                    "source": doc_data["id"],
                    "target": related_data["id"],
                    "type": type(rel_data).__name__,
                    "properties": dict(rel_data)
                })
        
        return {
            "entities": entities,
            "relationships": relationships,
            "total_entities": len(entities),
            "total_relationships": len(relationships)
        }
    
    def search_entities(self, entity_type: str = None, properties: Dict[str, Any] = None, 
                       limit: int = 100) -> List[Dict[str, Any]]:
        """ì—”í‹°í‹° ê²€ìƒ‰"""
        where_clauses = []
        params = {"limit": limit}
        
        # ì—”í‹°í‹° íƒ€ì… í•„í„°
        if entity_type:
            node_pattern = f"n:{entity_type}"
        else:
            node_pattern = "n"
        
        # ì†ì„± í•„í„°
        if properties:
            for i, (key, value) in enumerate(properties.items()):
                param_name = f"prop_{i}"
                if isinstance(value, str) and "*" in value:
                    # ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰
                    where_clauses.append(f"n.{key} CONTAINS ${param_name}")
                    params[param_name] = value.replace("*", "")
                else:
                    where_clauses.append(f"n.{key} = ${param_name}")
                    params[param_name] = value
        
        where_clause = " AND ".join(where_clauses)
        if where_clause:
            where_clause = f"WHERE {where_clause}"
        
        query = f"""
        MATCH ({node_pattern})
        {where_clause}
        RETURN n
        LIMIT $limit
        """
        
        results = self.execute_query(query, params)
        
        entities = []
        for record in results:
            node_data = record.get("n")
            if node_data:
                entity_type = "Unknown"
                if hasattr(node_data, 'labels') and node_data.labels:
                    entity_type = list(node_data.labels)[0]
                
                entities.append({
                    "id": node_data.get("id"),
                    "type": entity_type,
                    "properties": dict(node_data)
                })
        
        return entities
    
    def get_database_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´"""
        stats = {}
        
        try:
            # ì „ì²´ ë…¸ë“œ ìˆ˜
            result = self.execute_query("MATCH (n) RETURN count(n) as node_count")
            stats["total_nodes"] = result[0]["node_count"] if result else 0
            
            # ì „ì²´ ê´€ê³„ ìˆ˜
            result = self.execute_query("MATCH ()-[r]->() RETURN count(r) as rel_count")
            stats["total_relationships"] = result[0]["rel_count"] if result else 0
            
            # ë…¸ë“œ íƒ€ì…ë³„ ê°œìˆ˜
            result = self.execute_query("MATCH (n) RETURN labels(n) as labels, count(n) as count")
            node_types = {}
            for record in result:
                labels = record.get("labels", [])
                if labels:
                    label = labels[0]
                    node_types[label] = record.get("count", 0)
            stats["node_types"] = node_types
            
            # ê´€ê³„ íƒ€ì…ë³„ ê°œìˆ˜  
            result = self.execute_query("MATCH ()-[r]->() RETURN type(r) as type, count(r) as count")
            relationship_types = {}
            for record in result:
                rel_type = record.get("type")
                if rel_type:
                    relationship_types[rel_type] = record.get("count", 0)
            stats["relationship_types"] = relationship_types
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            stats["error"] = str(e)
        
        return stats
    
    def export_kg_to_file(self, output_path: str, format: str = "json") -> bool:
        """KG ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            if format.lower() == "json":
                return self._export_to_json(output_path)
            elif format.lower() == "cypher":
                return self._export_to_cypher(output_path)
            else:
                self.logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
                return False
        except Exception as e:
            self.logger.error(f"ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return False
    
    def _export_to_json(self, output_path: str) -> bool:
        """JSON í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        # ëª¨ë“  ë…¸ë“œ ì¡°íšŒ
        nodes_result = self.execute_query("MATCH (n) RETURN n")
        nodes = []
        for record in nodes_result:
            node_data = record.get("n")
            if node_data:
                entity_type = "Unknown"
                if hasattr(node_data, 'labels') and node_data.labels:
                    entity_type = list(node_data.labels)[0]
                
                nodes.append({
                    "id": node_data.get("id"),
                    "type": entity_type,
                    "properties": dict(node_data)
                })
        
        # ëª¨ë“  ê´€ê³„ ì¡°íšŒ
        rels_result = self.execute_query("""
            MATCH (source)-[r]->(target)
            RETURN source.id as source_id, target.id as target_id, 
                   type(r) as rel_type, properties(r) as rel_props
        """)
        
        relationships = []
        for record in rels_result:
            relationships.append({
                "source": record.get("source_id"),
                "target": record.get("target_id"),
                "type": record.get("rel_type"),
                "properties": record.get("rel_props", {})
            })
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        export_data = {
            "entities": nodes,
            "relationships": relationships,
            "exported_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_entities": len(nodes),
            "total_relationships": len(relationships)
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"âœ… JSON ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path}")
        return True
    
    def _export_to_cypher(self, output_path: str) -> bool:
        """Cypher ìŠ¤í¬ë¦½íŠ¸ë¡œ ë‚´ë³´ë‚´ê¸°"""
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("// DocExtract KG Export - Cypher Script\n")
            f.write(f"// Exported at: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            f.write("// Clear existing data\n")
            f.write("MATCH (n) DETACH DELETE n;\n\n")
            
            # ë…¸ë“œ ìƒì„± ì¿¼ë¦¬
            f.write("// Create nodes\n")
            nodes_result = self.execute_query("MATCH (n) RETURN n")
            for record in nodes_result:
                node_data = record.get("n")
                if node_data:
                    entity_type = "Unknown"
                    if hasattr(node_data, 'labels') and node_data.labels:
                        entity_type = list(node_data.labels)[0]
                    
                    props_str = ", ".join([f"{k}: {json.dumps(v)}" for k, v in node_data.items()])
                    f.write(f"CREATE (:{entity_type} {{{props_str}}});\n")
            
            f.write("\n// Create relationships\n")
            rels_result = self.execute_query("""
                MATCH (source)-[r]->(target)
                RETURN source.id as source_id, target.id as target_id, 
                       type(r) as rel_type, properties(r) as rel_props
            """)
            
            for record in rels_result:
                source_id = record.get("source_id")
                target_id = record.get("target_id") 
                rel_type = record.get("rel_type")
                rel_props = record.get("rel_props", {})
                
                props_str = ""
                if rel_props:
                    props_str = " {" + ", ".join([f"{k}: {json.dumps(v)}" for k, v in rel_props.items()]) + "}"
                
                f.write(f"MATCH (s {{id: {json.dumps(source_id)}}}) ")
                f.write(f"MATCH (t {{id: {json.dumps(target_id)}}}) ")
                f.write(f"CREATE (s)-[:{rel_type}{props_str}]->(t);\n")
        
        self.logger.info(f"âœ… Cypher ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_path}")
        return True


def create_memgraph_service(config: Dict[str, Any] = None) -> MemgraphService:
    """Memgraph ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    if config is None:
        config = {}
    
    return MemgraphService(
        uri=config.get("uri", "bolt://localhost:7687"),
        username=config.get("username", ""),
        password=config.get("password", "")
    )