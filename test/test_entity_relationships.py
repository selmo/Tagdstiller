#!/usr/bin/env python3
"""
ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸

ì‚¬ìš©ë²•:
cd /Users/selmo/Workspaces/DocExtract
PYTHONPATH=backend python test/test_entity_relationships.py
"""

import sys
import os
import json
from pathlib import Path

# ë°±ì—”ë“œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

from services.hierarchical_kg_builder import HierarchicalKGBuilder

def test_entity_relationships():
    """ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ê²½ë¡œ
    test_doc_path = "test/hierarchical_kg_test_document.md"
    
    print("ğŸ§ª ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: {test_doc_path}")
    
    # ë¬¸ì„œ ì½ê¸°
    try:
        with open(test_doc_path, 'r', encoding='utf-8') as f:
            document_text = f.read()
    except FileNotFoundError:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_doc_path}")
        return
    
    # ëª¨ì˜ í‚¤ì›Œë“œ ë°ì´í„° ìƒì„±
    mock_keywords = {
        "llm": [
            {"keyword": "FastAPI", "score": 0.95, "category": "technology"},
            {"keyword": "PostgreSQL", "score": 0.92, "category": "database"},
            {"keyword": "SQLAlchemy", "score": 0.88, "category": "framework"},
            {"keyword": "Redis", "score": 0.85, "category": "database"},
            {"keyword": "Docker", "score": 0.82, "category": "tool"},
            {"keyword": "RESTful", "score": 0.90, "category": "concept"},
            {"keyword": "JWT", "score": 0.87, "category": "technology"}
        ]
    }
    
    # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
    metadata = {
        "name": "hierarchical_kg_test_document.md",
        "size": len(document_text),
        "extension": ".md"
    }
    
    # ê³„ì¸µì  KG ë¹Œë” ìƒì„± (Memgraph ë¹„í™œì„±í™”)
    kg_builder = HierarchicalKGBuilder(auto_save_to_memgraph=False)
    
    print("ğŸ—ï¸ ê³„ì¸µì  KG êµ¬ì¶• ì¤‘...")
    
    # KG êµ¬ì¶•
    result = kg_builder.build_hierarchical_knowledge_graph(
        file_path=test_doc_path,
        document_text=document_text,
        keywords=mock_keywords,
        metadata=metadata,
        force_rebuild=True
    )
    
    print(f"âœ… KG êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ ì—”í‹°í‹°: {len(result['entities'])}ê°œ")
    print(f"ğŸ”— ì´ ê´€ê³„: {len(result['relationships'])}ê°œ")
    
    # ê´€ê³„ ìœ í˜•ë³„ ë¶„ì„
    relationship_types = {}
    entity_to_entity_relationships = []
    
    for rel in result["relationships"]:
        rel_name = rel.get("properties", {}).get("relationship_name", "UNKNOWN")
        relationship_types[rel_name] = relationship_types.get(rel_name, 0) + 1
        
        # ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„ í•„í„°ë§
        if rel.get("properties", {}).get("entity_to_entity"):
            entity_to_entity_relationships.append(rel)
    
    print(f"\nğŸ“ˆ ê´€ê³„ ìœ í˜• ë¶„í¬:")
    for rel_type, count in sorted(relationship_types.items()):
        print(f"  - {rel_type}: {count}ê°œ")
    
    print(f"\nğŸ¯ ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„: {len(entity_to_entity_relationships)}ê°œ")
    
    if entity_to_entity_relationships:
        print("\nğŸ” ì—”í‹°í‹° ê°„ ê´€ê³„ ìƒì„¸:")
        
        # ì—”í‹°í‹° IDë¥¼ í…ìŠ¤íŠ¸ë¡œ ë§¤í•‘í•˜ëŠ” ë§µ ìƒì„±
        entity_text_map = {}
        for entity in result["entities"]:
            if entity.get("properties", {}).get("hierarchical_entity"):
                entity_text_map[entity["id"]] = entity.get("properties", {}).get("text", entity["id"])
        
        for i, rel in enumerate(entity_to_entity_relationships[:10], 1):  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            source_text = entity_text_map.get(rel["source"], rel["source"])
            target_text = entity_text_map.get(rel["target"], rel["target"])
            rel_name = rel.get("properties", {}).get("relationship_name", "UNKNOWN")
            confidence = rel.get("properties", {}).get("confidence_score", 0)
            extraction_method = rel.get("properties", {}).get("extraction_method", "unknown")
            
            print(f"  {i:2d}. {source_text} --[{rel_name}]--> {target_text}")
            print(f"      ì‹ ë¢°ë„: {confidence:.2f}, ì¶”ì¶œë°©ë²•: {extraction_method}")
            
            if rel.get("properties", {}).get("context_snippet"):
                context = rel["properties"]["context_snippet"]
                print(f"      ì»¨í…ìŠ¤íŠ¸: \"{context}\"")
            print()
    else:
        print("âš ï¸  ì—”í‹°í‹° ê°„ ì§ì ‘ ê´€ê³„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
        print(f"\nğŸ” ë””ë²„ê¹… ì •ë³´:")
        
        keyword_entities = [e for e in result["entities"] if e.get("properties", {}).get("hierarchical_entity")]
        print(f"  - í‚¤ì›Œë“œ ì—”í‹°í‹° ìˆ˜: {len(keyword_entities)}ê°œ")
        
        if keyword_entities:
            print(f"  - í‚¤ì›Œë“œ ì—”í‹°í‹° ìƒ˜í”Œ:")
            for entity in keyword_entities[:5]:
                entity_text = entity.get("properties", {}).get("text", "")
                entity_type = entity.get("type", "")
                source_structure = entity.get("properties", {}).get("source_structure", "")
                print(f"    * {entity_text} ({entity_type}) from {source_structure}")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    output_file = "test/entity_relationships_test_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_entity_relationships()