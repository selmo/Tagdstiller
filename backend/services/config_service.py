from sqlalchemy.orm import Session
from db.models import Config
from typing import Dict, Any, Optional
import json
import requests
import logging
from .config_cache import config_cache

class ConfigService:
    """Service for managing application configuration."""
    
    logger = logging.getLogger(__name__)
    
    # Default configuration values for keyword extraction and API settings
    DEFAULT_CONFIGS = {
        # Keyword extraction settings
        "extractor.default_method": {
            "value": "keybert",
            "description": "ê¸°ë³¸ ì¶”ì¶œ ë°©ë²•"
        },
        "extractor.keybert.enabled": {
            "value": "true",
            "description": "í™œì„±í™”"
        },
        "extractor.keybert.model": {
            "value": "all-MiniLM-L6-v2",
            "description": "ëª¨ë¸"
        },
        "extractor.keybert.use_mmr": {
            "value": "true",
            "description": "MMR ì‚¬ìš©"
        },
        "extractor.keybert.use_maxsum": {
            "value": "false",
            "description": "MaxSum ì‚¬ìš©"
        },
        "extractor.keybert.diversity": {
            "value": "0.5",
            "description": "ë‹¤ì–‘ì„± (0.0-1.0)"
        },
        "extractor.keybert.keyphrase_ngram_range": {
            "value": "[1, 2]",
            "description": "N-gram ë²”ìœ„"
        },
        "extractor.keybert.stop_words": {
            "value": "english",
            "description": "ë¶ˆìš©ì–´ ì–¸ì–´"
        },
        "extractor.keybert.max_keywords": {
            "value": "10",
            "description": "ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜"
        },
        "extractor.ner.enabled": {
            "value": "true", 
            "description": "í™œì„±í™”"
        },
        "extractor.ner.model": {
            "value": "ko_core_news_sm",
            "description": "ëª¨ë¸"
        },
        "extractor.ner.auto_download": {
            "value": "true",
            "description": "ìžë™ ë‹¤ìš´ë¡œë“œ"
        },
        "extractor.konlpy.enabled": {
            "value": "true",
            "description": "í™œì„±í™”"
        },
        "extractor.konlpy.tagger": {
            "value": "Okt",
            "description": "í˜•íƒœì†Œ ë¶„ì„ê¸°"
        },
        "extractor.konlpy.min_length": {
            "value": "2",
            "description": "ìµœì†Œ ê¸€ìž ìˆ˜"
        },
        "extractor.konlpy.min_frequency": {
            "value": "1",
            "description": "ìµœì†Œ ë¹ˆë„"
        },
        "extractor.konlpy.max_keywords": {
            "value": "15",
            "description": "ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜"
        },
        
        # LLM ì„¤ì • (Provider + Ollama/OpenAI/Gemini)
        "LLM_PROVIDER": {
            "value": "ollama",
            "description": "LLM ì œê³µìž (ollama|openai|gemini)"
        },
        # Ollama
        "OLLAMA_BASE_URL": {
            "value": "http://localhost:11434",
            "description": "ì„œë²„ ì£¼ì†Œ"
        },
        "OLLAMA_MODEL": {
            "value": "mistral",
            "description": "ëª¨ë¸"
        },
        "OLLAMA_TIMEOUT": {
            "value": "30",
            "description": "íƒ€ìž„ì•„ì›ƒ (ì´ˆ)"
        },
        "OLLAMA_MAX_TOKENS": {
            "value": "1000",
            "description": "ìµœëŒ€ í† í°"
        },
        "OLLAMA_TEMPERATURE": {
            "value": "0.3",
            "description": "ì˜¨ë„ (0.0-1.0)"
        },
        "ENABLE_LLM_EXTRACTION": {
            "value": "false",
            "description": "LLM ì¶”ì¶œ í™œì„±í™”"
        },
        
        # OpenAI ì„¤ì •
        "OPENAI_BASE_URL": {
            "value": "https://api.openai.com/v1",
            "description": "API Base URL"
        },
        "OPENAI_API_KEY": {
            "value": "",
            "description": "API í‚¤"
        },
        "OPENAI_MODEL": {
            "value": "gpt-3.5-turbo",
            "description": "ëª¨ë¸"
        },
        "OPENAI_MAX_TOKENS": {
            "value": "1000",
            "description": "ìµœëŒ€ í† í°"
        },
        "OPENAI_TEMPERATURE": {
            "value": "0.2",
            "description": "ì˜¨ë„ (0.0-1.0)"
        },

        # Gemini ì„¤ì •
        "GEMINI_API_BASE": {
            "value": "https://generativelanguage.googleapis.com",
            "description": "API Base URL"
        },
        "GEMINI_API_KEY": {
            "value": "",
            "description": "API í‚¤"
        },
        "GEMINI_MODEL": {
            "value": "models/gemini-1.5-pro",
            "description": "ëª¨ë¸ ì´ë¦„ (v1beta)"
        },
        "GEMINI_MAX_TOKENS": {
            "value": "1000",
            "description": "ìµœëŒ€ í† í°"
        },
        "GEMINI_TEMPERATURE": {
            "value": "0.2",
            "description": "ì˜¨ë„ (0.0-1.0)"
        },
        
        # íŒŒì¼ ì²˜ë¦¬ ì„¤ì •
        "FILE_MAX_SIZE_MB": {
            "value": "50",
            "description": "ìµœëŒ€ í¬ê¸° (MB)"
        },
        "ALLOWED_EXTENSIONS": {
            "value": json.dumps([".txt", ".pdf", ".docx", ".html", ".md", ".hwp"]),
            "description": "í—ˆìš© í™•ìž¥ìž"
        },
        
        # LangExtract ì„¤ì • (API í˜¸í™˜ì„± ë¬¸ì œë¡œ ë¹„í™œì„±í™”)
        "extractor.langextract.enabled": {
            "value": "false",
            "description": "í™œì„±í™”"
        },
        "extractor.langextract.max_keywords": {
            "value": "15",
            "description": "ìµœëŒ€ í‚¤ì›Œë“œ ìˆ˜"
        },
        "extractor.langextract.chunk_size": {
            "value": "2000",
            "description": "ì²­í¬ í¬ê¸°"
        },
        "extractor.langextract.overlap": {
            "value": "200",
            "description": "ì²­í¬ ì˜¤ë²„ëž©"
        },
        "extractor.langextract.confidence_threshold": {
            "value": "0.6",
            "description": "ì‹ ë¢°ë„ ìž„ê³„ê°’ (0.0-1.0)"
        },
        
        # Metadata ì¶”ì¶œê¸° ì„¤ì •
        "extractor.metadata.enabled": {
            "value": "true",
            "description": "í™œì„±í™”"
        },
        "extractor.metadata.extract_structure": {
            "value": "true",
            "description": "êµ¬ì¡° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
        },
        "extractor.metadata.extract_statistics": {
            "value": "true", 
            "description": "í†µê³„ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
        },
        "extractor.metadata.extract_content": {
            "value": "true",
            "description": "ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
        },
        "extractor.metadata.extract_file_info": {
            "value": "true",
            "description": "íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
        },
        "extractor.metadata.extract_summary": {
            "value": "true",
            "description": "ë¬¸ì„œ ìš”ì•½ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"
        },
        "extractor.metadata.llm_summary": {
            "value": "true",
            "description": "LLM ê¸°ë°˜ ìš”ì•½ ì‚¬ìš© (ë¹„í™œì„±í™” ì‹œ ê·œì¹™ ê¸°ë°˜ ìš”ì•½)"
        },
        "extractor.metadata.include_filename": {
            "value": "true",
            "description": "íŒŒì¼ëª… í‚¤ì›Œë“œ í¬í•¨"
        },
        "extractor.metadata.min_heading_length": {
            "value": "2",
            "description": "ìµœì†Œ ì œëª© ê¸¸ì´"
        },
        "extractor.metadata.max_metadata_keywords": {
            "value": "20",
            "description": "ìµœëŒ€ ë©”íƒ€ë°ì´í„° í‚¤ì›Œë“œ ìˆ˜"
        },
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        "prompt.keyword_extraction.language": {
            "value": "auto",
            "description": "í‚¤ì›Œë“œ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ì–¸ì–´ (auto, ko, en)"
        },
        "prompt.keyword_extraction.domain": {
            "value": "general",
            "description": "í‚¤ì›Œë“œ ì¶”ì¶œ ë„ë©”ì¸ (general, academic, technical)"
        },
        "prompt.keyword_extraction.max_keywords": {
            "value": "20",
            "description": "í‚¤ì›Œë“œ ì¶”ì¶œ ìµœëŒ€ ê°œìˆ˜"
        },
        "prompt.keyword_extraction.temperature": {
            "value": "0.1",
            "description": "í‚¤ì›Œë“œ ì¶”ì¶œ LLM ì˜¨ë„"
        },
        "prompt.keyword_extraction.max_tokens": {
            "value": "500",
            "description": "í‚¤ì›Œë“œ ì¶”ì¶œ ìµœëŒ€ í† í° ìˆ˜"
        },
        "prompt.document_summary.language": {
            "value": "auto",
            "description": "ë¬¸ì„œ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì–¸ì–´ (auto, ko, en)"
        },
        "prompt.document_summary.domain": {
            "value": "general",
            "description": "ë¬¸ì„œ ìš”ì•½ ë„ë©”ì¸ (general, academic, technical)"
        },
        "prompt.document_summary.temperature": {
            "value": "0.3",
            "description": "ë¬¸ì„œ ìš”ì•½ LLM ì˜¨ë„"
        },
        "prompt.document_summary.max_tokens": {
            "value": "1000",
            "description": "ë¬¸ì„œ ìš”ì•½ ìµœëŒ€ í† í° ìˆ˜"
        },
        "prompt.document_summary.chunk_size": {
            "value": "4000",
            "description": "ë¬¸ì„œ ì²­í‚¹ í¬ê¸°"
        },
        "prompt.metadata_extraction.language": {
            "value": "ko",
            "description": "ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ì–¸ì–´"
        },
        "prompt.metadata_extraction.temperature": {
            "value": "0.2",
            "description": "ë©”íƒ€ë°ì´í„° ì¶”ì¶œ LLM ì˜¨ë„"
        },
        "prompt.metadata_extraction.max_tokens": {
            "value": "800",
            "description": "ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ìµœëŒ€ í† í° ìˆ˜"
        },
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì €ìž¥ ê³µê°„
        "custom_prompts": {
            "value": "{}",
            "description": "ì‚¬ìš©ìž ì •ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"
        },
        
        # ê¸°ë³¸ ì¶”ì¶œê¸° ì„¤ì • (LLMë§Œ ì‚¬ìš©)
        "DEFAULT_EXTRACTORS": {
            "value": json.dumps(["llm"]),
            "description": "ê¸°ë³¸ ì¶”ì¶œê¸°"
        },
        "MAX_KEYWORDS_PER_DOCUMENT": {
            "value": "20",
            "description": "ë¬¸ì„œë‹¹ ìµœëŒ€ í‚¤ì›Œë“œ"
        },
        
        # ì¼ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
        "APP_DEBUG_MODE": {
            "value": "false",
            "description": "ë””ë²„ê·¸ ëª¨ë“œ"
        },
        
        # ë¡œì»¬ íŒŒì¼ ë¶„ì„ ì„¤ì •
        "LOCAL_FILE_ROOT": {
            "value": "./data/uploads",
            "description": "ë¡œì»¬ íŒŒì¼ ë¶„ì„ ë£¨íŠ¸ ë””ë ‰í† ë¦¬"
        }
    }
    
    @classmethod
    def initialize_default_configs(cls, db: Session) -> None:
        """Initialize default configuration values if they don't exist."""
        # ì¤‘ë³µ ì„¤ì • ì œê±° ë° ë§ˆì´ê·¸ë ˆì´ì…˜
        deprecated_keys = [
            # ê¸°ì¡´ ollama.* ì„¤ì •ë“¤
            "ollama.base_url", "ollama.model", "ollama.timeout",
            # ì¤‘ë³µ LLM ì„¤ì •ë“¤
            "extractor.llm.enabled", "extractor.llm.provider", "extractor.llm.model", 
            "extractor.llm.max_tokens", "extractor.llm.temperature",
            # ì‚¬ìš©: LLM_PROVIDER (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
            # ì¤‘ë³µ íŒŒì¼ ì„¤ì •ë“¤
            "file.allowed_extensions", "file.max_size_mb",
            # ì¤‘ë³µ í‚¤ì›Œë“œ ê°œìˆ˜ ì„¤ì •ë“¤
            "app.max_keywords", "app.debug_mode",
            # ê¸°ì¡´ OpenAI ì„¤ì •ë“¤
            "openai.api_key", "openai.model", "openai.max_tokens",
            # ì¼ê´€ì„± ì—†ëŠ” KeyBERT ì„¤ì •ë“¤
            "KeyBERT_ENABLED", "KeyBERT_MODEL", "KeyBERT_MMR"
        ]
        
        removed_count = 0
        for key in deprecated_keys:
            deprecated_config = db.query(Config).filter(Config.key == key).first()
            if deprecated_config:
                print(f"Removing deprecated config: {key}")
                db.delete(deprecated_config)
                removed_count += 1
        
        # ìƒˆ ì„¤ì • ì¶”ê°€
        added_count = 0
        for key, config_data in cls.DEFAULT_CONFIGS.items():
            existing_config = db.query(Config).filter(Config.key == key).first()
            if not existing_config:
                config = Config(
                    key=key,
                    value=config_data["value"],
                    description=config_data["description"]
                )
                db.add(config)
                added_count += 1
        
        db.commit()
        print(f"Configuration migration completed: removed {removed_count} deprecated configs, added {added_count} new configs")
        
        # Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ (ì¼ì‹œ ë¹„í™œì„±í™” - startup ì†ë„ ê°œì„ )
        # cls._test_ollama_connection(db)
        print("â„¹ï¸ Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ - /llm/test_connection APIë¡œ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥")
    
    @classmethod
    def _check_and_configure_ollama(cls, db: Session) -> None:
        """Check Ollama server connection and configure default model."""
        cls.logger.info("ðŸ” Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        print("ðŸ” Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œìž‘...")
        try:
            ollama_url = cls.get_config_value(db, "OLLAMA_BASE_URL", "http://localhost:11434")
            current_model = cls.get_config_value(db, "OLLAMA_MODEL", "mistral")
            cls.logger.info(f"ðŸ“ Ollama URL: {ollama_url}, í˜„ìž¬ ëª¨ë¸: {current_model}")
            print(f"ðŸ“ Ollama URL: {ollama_url}, í˜„ìž¬ ëª¨ë¸: {current_model}")
            
            # Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ (ë” ì§§ì€ íƒ€ìž„ì•„ì›ƒìœ¼ë¡œ ë¹ ë¥¸ ì‹¤íŒ¨)
            response = requests.get(f"{ollama_url}/api/tags", timeout=2)
            if response.status_code == 200:
                available_models = [model['name'] for model in response.json().get('models', [])]
                
                if available_models:
                    cls.logger.info(f"Ollama ì„œë²„ ì—°ê²° ì„±ê³µ. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {len(available_models)}ê°œ")
                    
                    # í˜„ìž¬ ì„¤ì •ëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
                    if current_model not in available_models:
                        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ìžë™ ì„ íƒ
                        preferred_models = [
                            "phi3.5:latest", "phi3:latest", "mistral:latest", "llama3.2:latest",
                            "qwen2.5:latest", "gemma2:latest", "deepseek-r1:latest"
                        ]
                        
                        selected_model = None
                        for preferred in preferred_models:
                            if preferred in available_models:
                                selected_model = preferred
                                break
                        
                        # ìš°ì„ ìˆœìœ„ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ
                        if not selected_model:
                            selected_model = available_models[0]
                        
                        # ëª¨ë¸ ì—…ë°ì´íŠ¸
                        config = db.query(Config).filter(Config.key == "OLLAMA_MODEL").first()
                        if config:
                            old_model = config.value
                            config.value = selected_model
                            db.commit()
                            config_cache.invalidate("OLLAMA_MODEL")
                            cls.logger.info(f"ðŸ”„ Ollama ëª¨ë¸ ìžë™ ë³€ê²½: {old_model} â†’ {selected_model}")
                            print(f"ðŸ”„ Ollama ëª¨ë¸ ìžë™ ë³€ê²½: {old_model} â†’ {selected_model}")
                    else:
                        cls.logger.info(f"âœ… Ollama ëª¨ë¸ '{current_model}' ì‚¬ìš© ê°€ëŠ¥")
                        print(f"âœ… Ollama ëª¨ë¸ '{current_model}' ì‚¬ìš© ê°€ëŠ¥")
                else:
                    cls.logger.warning("âš ï¸ Ollamaì— ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
                    print("âš ï¸ Ollamaì— ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            else:
                cls.logger.warning(f"âš ï¸ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.status_code}")
                print(f"âš ï¸ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            cls.logger.warning("âš ï¸ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Ollamaë¥¼ ì‹œìž‘í•˜ì„¸ìš”.")
            print("âš ï¸ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Ollamaë¥¼ ì‹œìž‘í•˜ì„¸ìš”.")
        except requests.exceptions.Timeout:
            cls.logger.warning("âš ï¸ Ollama ì„œë²„ ì—°ê²° íƒ€ìž„ì•„ì›ƒ")
            print("âš ï¸ Ollama ì„œë²„ ì—°ê²° íƒ€ìž„ì•„ì›ƒ")
        except Exception as e:
            cls.logger.error(f"âŒ Ollama ì„¤ì • í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            print(f"âŒ Ollama ì„¤ì • í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    @classmethod
    def _test_ollama_connection(cls, db: Session) -> None:
        """Test Ollama server connection using /api/tags endpoint."""
        try:
            ollama_url = cls.get_config_value(db, "OLLAMA_BASE_URL", "http://localhost:11434")
            
            # ì§§ì€ íƒ€ìž„ì•„ì›ƒìœ¼ë¡œ ë¹ ë¥¸ ì—°ê²° í…ŒìŠ¤íŠ¸
            response = requests.get(f"{ollama_url}/api/tags", timeout=1)
            if response.status_code == 200:
                model_count = len(response.json().get('models', []))
                cls.logger.info(f"âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ - {model_count}ê°œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
                print(f"âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ - {model_count}ê°œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
            else:
                cls.logger.warning(f"âš ï¸ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.status_code}")
                print(f"âš ï¸ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            cls.logger.info("â„¹ï¸ Ollama ì„œë²„ ë¯¸ì—°ê²° (LLM ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
            print("â„¹ï¸ Ollama ì„œë²„ ë¯¸ì—°ê²° (LLM ê¸°ëŠ¥ ë¹„í™œì„±í™”)")
        except requests.exceptions.Timeout:
            cls.logger.warning("âš ï¸ Ollama ì„œë²„ ì—°ê²° íƒ€ìž„ì•„ì›ƒ")
            print("âš ï¸ Ollama ì„œë²„ ì—°ê²° íƒ€ìž„ì•„ì›ƒ")
        except Exception as e:
            cls.logger.warning(f"âš ï¸ Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            print(f"âš ï¸ Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
    
    @classmethod
    def get_config_value(cls, db: Session, key: str, default: Any = None) -> Any:
        """Get a configuration value with optional default. Uses cache for performance."""
        return config_cache.get(key, default, db)
    
    @classmethod
    def get_bool_config(cls, db: Session, key: str, default: bool = False) -> bool:
        """Get a configuration value as boolean."""
        value = cls.get_config_value(db, key, default)
        if isinstance(value, str):
            return value.lower() in ("true", "1", "yes", "on")
        return bool(value)
    
    @classmethod
    def get_int_config(cls, db: Session, key: str, default: int = 0) -> int:
        """Get a configuration value as integer."""
        value = cls.get_config_value(db, key, default)
        try:
            return int(value)
        except (ValueError, TypeError):
            return default
    
    @classmethod
    def get_float_config(cls, db: Session, key: str, default: float = 0.0) -> float:
        """Get a configuration value as float."""
        value = cls.get_config_value(db, key, default)
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    @classmethod
    def get_json_config(cls, db: Session, key: str, default: Any = None) -> Any:
        """Get a configuration value as parsed JSON."""
        value = cls.get_config_value(db, key)
        if value is None:
            return default
        
        try:
            return json.loads(value)
        except (json.JSONDecodeError, TypeError):
            return default
    
    @classmethod
    def update_config(cls, db: Session, key: str, value: Any, description: Optional[str] = None) -> Config:
        """Update or create a configuration value. Updates cache automatically."""
        config = db.query(Config).filter(Config.key == key).first()
        
        # Convert value to string for storage
        str_value = json.dumps(value) if isinstance(value, (dict, list)) else str(value)
        
        if config:
            config.value = str_value
            if description is not None:
                config.description = description
        else:
            config = Config(
                key=key,
                value=str_value,
                description=description
            )
            db.add(config)
        
        db.commit()
        db.refresh(config)
        
        # Update cache
        config_cache.set(key, value, db)
        
        return config
    
    @classmethod
    def _parse_config_value(cls, value: str) -> Any:
        """Parse a configuration value from string."""
        if not value:
            return value
        
        # Try to parse as JSON first (for lists, dicts, etc.)
        try:
            return json.loads(value)
        except json.JSONDecodeError:
            # Return as string if not valid JSON
            return value
    
    @classmethod
    def get_extractor_config(cls, db: Session) -> Dict[str, Any]:
        """Get all extractor-related configuration."""
        return {
            "default_method": cls.get_config_value(db, "extractor.default_method", "keybert"),
            "keybert_enabled": cls.get_bool_config(db, "extractor.keybert.enabled", True),
            "keybert_model": cls.get_config_value(db, "extractor.keybert.model", "all-MiniLM-L6-v2"),
            "keybert_use_mmr": cls.get_bool_config(db, "extractor.keybert.use_mmr", True),
            "keybert_use_maxsum": cls.get_bool_config(db, "extractor.keybert.use_maxsum", False),
            "keybert_diversity": cls.get_float_config(db, "extractor.keybert.diversity", 0.5),
            "keybert_keyphrase_ngram_range": cls.get_json_config(db, "extractor.keybert.keyphrase_ngram_range", [1, 2]),
            "keybert_stop_words": cls.get_config_value(db, "extractor.keybert.stop_words", "english"),
            "keybert_max_keywords": cls.get_int_config(db, "extractor.keybert.max_keywords", 10),
            "ner_enabled": cls.get_bool_config(db, "extractor.ner.enabled", True),
            "ner_model": cls.get_config_value(db, "extractor.ner.model", "ko_core_news_sm"),
            "ner_auto_download": cls.get_bool_config(db, "extractor.ner.auto_download", True),
            "llm_enabled": cls.get_bool_config(db, "ENABLE_LLM_EXTRACTION", False),
            "llm_provider": cls.get_config_value(db, "LLM_PROVIDER", "ollama"),
            "konlpy_enabled": cls.get_bool_config(db, "extractor.konlpy.enabled", False),
            "konlpy_tagger": cls.get_config_value(db, "extractor.konlpy.tagger", "Okt"),
            "konlpy_min_length": cls.get_int_config(db, "extractor.konlpy.min_length", 2),
            "konlpy_min_frequency": cls.get_int_config(db, "extractor.konlpy.min_frequency", 1),
            "konlpy_max_keywords": cls.get_int_config(db, "extractor.konlpy.max_keywords", 15),
            
            # LangExtract ì„¤ì • (API í˜¸í™˜ì„± ë¬¸ì œë¡œ ë¹„í™œì„±í™”)
            "langextract_enabled": cls.get_bool_config(db, "extractor.langextract.enabled", False),
            "langextract_max_keywords": cls.get_int_config(db, "extractor.langextract.max_keywords", 15),
            "langextract_chunk_size": cls.get_int_config(db, "extractor.langextract.chunk_size", 2000),
            "langextract_overlap": cls.get_int_config(db, "extractor.langextract.overlap", 200),
            "langextract_confidence_threshold": cls.get_float_config(db, "extractor.langextract.confidence_threshold", 0.6),
            
            # Metadata ì„¤ì •
            "metadata_enabled": cls.get_bool_config(db, "extractor.metadata.enabled", True),
            "metadata_extract_structure": cls.get_bool_config(db, "extractor.metadata.extract_structure", True),
            "metadata_extract_statistics": cls.get_bool_config(db, "extractor.metadata.extract_statistics", True),
            "metadata_extract_content": cls.get_bool_config(db, "extractor.metadata.extract_content", True),
            "metadata_extract_file_info": cls.get_bool_config(db, "extractor.metadata.extract_file_info", True),
            "metadata_extract_summary": cls.get_bool_config(db, "extractor.metadata.extract_summary", True),
            "metadata_llm_summary": cls.get_bool_config(db, "extractor.metadata.llm_summary", True),
            "metadata_include_filename": cls.get_bool_config(db, "extractor.metadata.include_filename", True),
            "metadata_min_heading_length": cls.get_int_config(db, "extractor.metadata.min_heading_length", 2),
            "metadata_max_metadata_keywords": cls.get_int_config(db, "extractor.metadata.max_metadata_keywords", 20),
            
            "max_keywords": cls.get_int_config(db, "app.max_keywords", 20)
        }
    
    @classmethod
    def get_ollama_config(cls, db: Session) -> Dict[str, Any]:
        """Get Ollama-specific configuration."""
        return {
            "base_url": cls.get_config_value(db, "OLLAMA_BASE_URL", "http://localhost:11434"),
            "model": cls.get_config_value(db, "OLLAMA_MODEL", "mistral"),
            "timeout": cls.get_int_config(db, "OLLAMA_TIMEOUT", 30)
        }

    @classmethod
    def get_openai_config(cls, db: Session) -> Dict[str, Any]:
        return {
            "base_url": cls.get_config_value(db, "OPENAI_BASE_URL", "https://api.openai.com/v1"),
            "api_key": cls.get_config_value(db, "OPENAI_API_KEY", ""),
            "model": cls.get_config_value(db, "OPENAI_MODEL", "gpt-3.5-turbo"),
            "max_tokens": cls.get_int_config(db, "OPENAI_MAX_TOKENS", 1000),
            "temperature": cls.get_float_config(db, "OPENAI_TEMPERATURE", 0.2),
        }

    @classmethod
    def get_gemini_config(cls, db: Session) -> Dict[str, Any]:
        return {
            "base_url": cls.get_config_value(db, "GEMINI_API_BASE", "https://generativelanguage.googleapis.com"),
            "api_key": cls.get_config_value(db, "GEMINI_API_KEY", ""),
            "model": cls.get_config_value(db, "GEMINI_MODEL", "models/gemini-1.5-pro"),
            "max_tokens": cls.get_int_config(db, "GEMINI_MAX_TOKENS", 1000),
            "temperature": cls.get_float_config(db, "GEMINI_TEMPERATURE", 0.2),
        }
